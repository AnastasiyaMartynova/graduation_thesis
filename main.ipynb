{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02b71340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in c:\\users\\anmrt\\desktop\\useful shit\\диплом\\graduation_thesis\\venv\\lib\\site-packages (3.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1da0fa69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\anmrt\\desktop\\useful shit\\диплом\\graduation_thesis\\venv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\anmrt\\desktop\\useful shit\\диплом\\graduation_thesis\\venv\\lib\\site-packages (from pandas) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\anmrt\\desktop\\useful shit\\диплом\\graduation_thesis\\venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anmrt\\desktop\\useful shit\\диплом\\graduation_thesis\\venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\anmrt\\desktop\\useful shit\\диплом\\graduation_thesis\\venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anmrt\\desktop\\useful shit\\диплом\\graduation_thesis\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b781372",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PyPDF2\n",
    "import pandas as pd\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1355fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pypdf import PdfReader\n",
    "\n",
    "#def extract_text_pypdf(pdf_path):\n",
    "#    reader = PdfReader(pdf_path)\n",
    "#    text = \"\"\n",
    "#    for page in reader.pages:\n",
    "#        text += page.extract_text()\n",
    "#    return text\n",
    "\n",
    "\n",
    "#pdf_file = \"test_data_pdf/IPI-(2012-1).pdf\" \n",
    "#extracted_text = extract_text_pypdf(pdf_file)\n",
    "#print(extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49d5f562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebc6fd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обработан: IPI(2012-3)-full.pdf\n",
      "Обработан: IPI-(2012-1).pdf\n",
      "Обработан: IPI-(2012-2)full.pdf\n",
      "Обработан: IPI-(2012-4).pdf\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "def text_extraction(folder_path):\n",
    "    \n",
    "    data = []\n",
    "    pdf_files = [f for f in os.listdir(folder_path) if f.endswith('.pdf')]\n",
    "    \n",
    "    for pdf_file in sorted(pdf_files):\n",
    "        file_path = os.path.join(folder_path, pdf_file)\n",
    "        text = \"\"\n",
    "        \n",
    "        try:\n",
    "            with open(file_path, 'rb') as file:\n",
    "                pdf_reader = PyPDF2.PdfReader(file)\n",
    "                for page in pdf_reader.pages:\n",
    "                    text += page.extract_text() + \"\\n\"\n",
    "            \n",
    "            data.append({\n",
    "                'file_name': pdf_file,\n",
    "                'text': text,\n",
    "                'text_length': len(text)\n",
    "            })\n",
    "            print(f\"Обработан: {pdf_file}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка с {pdf_file}: {e}\")\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    folder = \"test_data_pdf\"\n",
    "    if os.path.exists(folder):\n",
    "        df = text_extraction(folder)\n",
    "        if not df.empty:\n",
    "            df.to_csv(\"journal_dataset_1.csv\", index=False, encoding='utf-8')\n",
    "            print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "708c5711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\anmrt\\desktop\\useful shit\\диплом\\graduation_thesis\\venv\\lib\\site-packages (3.10.7)\n",
      "Requirement already satisfied: seaborn in c:\\users\\anmrt\\desktop\\useful shit\\диплом\\graduation_thesis\\venv\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\anmrt\\desktop\\useful shit\\диплом\\graduation_thesis\\venv\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\anmrt\\desktop\\useful shit\\диплом\\graduation_thesis\\venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\anmrt\\desktop\\useful shit\\диплом\\graduation_thesis\\venv\\lib\\site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\anmrt\\desktop\\useful shit\\диплом\\graduation_thesis\\venv\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\anmrt\\desktop\\useful shit\\диплом\\graduation_thesis\\venv\\lib\\site-packages (from matplotlib) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\anmrt\\desktop\\useful shit\\диплом\\graduation_thesis\\venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\anmrt\\desktop\\useful shit\\диплом\\graduation_thesis\\venv\\lib\\site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\anmrt\\desktop\\useful shit\\диплом\\graduation_thesis\\venv\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\anmrt\\desktop\\useful shit\\диплом\\graduation_thesis\\venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\anmrt\\desktop\\useful shit\\диплом\\graduation_thesis\\venv\\lib\\site-packages (from seaborn) (2.3.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anmrt\\desktop\\useful shit\\диплом\\graduation_thesis\\venv\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\anmrt\\desktop\\useful shit\\диплом\\graduation_thesis\\venv\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anmrt\\desktop\\useful shit\\диплом\\graduation_thesis\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib seaborn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bf1e100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\anmrt\\desktop\\useful shit\\диплом\\graduation_thesis\\venv\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: click in c:\\users\\anmrt\\desktop\\useful shit\\диплом\\graduation_thesis\\venv\\lib\\site-packages (from nltk) (8.3.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\anmrt\\desktop\\useful shit\\диплом\\graduation_thesis\\venv\\lib\\site-packages (from nltk) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\anmrt\\desktop\\useful shit\\диплом\\graduation_thesis\\venv\\lib\\site-packages (from nltk) (2025.10.23)\n",
      "Requirement already satisfied: tqdm in c:\\users\\anmrt\\desktop\\useful shit\\диплом\\graduation_thesis\\venv\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\anmrt\\desktop\\useful shit\\диплом\\graduation_thesis\\venv\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5abec32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Dict, Tuple\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83b9ffb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              file_name                                               text  \\\n",
      "0  IPI(2012-3)-full.pdf  Информатика  и её применения  \\n \\nТом 6 Выпус...   \n",
      "1      IPI-(2012-1).pdf  Информатика  и её применения  \\n \\nТом 6 Выпус...   \n",
      "2  IPI-(2012-2)full.pdf  Информатика  и её применения  \\n \\nТом 6 Выпус...   \n",
      "3      IPI-(2012-4).pdf  Информатика  и её применения  \\nТом 6   Выпуск...   \n",
      "\n",
      "   text_length  \n",
      "0       465685  \n",
      "1       507646  \n",
      "2       490996  \n",
      "3       410020  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"journal_dataset_1.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86d39952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text: str) -> List[str]:\n",
    "\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    \n",
    "    text = text.lower() # Нижний регистр\n",
    "    \n",
    "    text = re.sub(r'[^\\w\\s\\.\\,\\-\\+\\=\\*\\/\\(\\)\\[\\]\\{\\}\\^]', ' ', text) # Удаление спец символов с сохранением мат обозначений (вроде бы)\n",
    "    \n",
    "    text = re.sub(r'\\s+', ' ', text) # Лишние проблелы\n",
    "    \n",
    "    # Токенизация\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # Удалить стоп-слова\n",
    "    from nltk.corpus import stopwords\n",
    "\n",
    "    stop_words = set(stopwords.words('russian') + stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words and len(token) > 2]\n",
    "\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40bbfd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = df['text'].apply(preprocess_text)\n",
    "df['processed_text'] = df['tokens'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb3e4462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180073\n"
     ]
    }
   ],
   "source": [
    "print(sum(len(tokens) for tokens in df['tokens']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7595d08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\anmrt\\desktop\\useful shit\\диплом\\graduation_thesis\\venv\\lib\\site-packages (4.4.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\anmrt\\desktop\\useful shit\\диплом\\graduation_thesis\\venv\\lib\\site-packages (from gensim) (2.3.4)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\anmrt\\desktop\\useful shit\\диплом\\graduation_thesis\\venv\\lib\\site-packages (from gensim) (1.16.3)\n",
      "Requirement already satisfied: smart_open>=1.8.1 in c:\\users\\anmrt\\desktop\\useful shit\\диплом\\graduation_thesis\\venv\\lib\\site-packages (from gensim) (7.4.2)\n",
      "Requirement already satisfied: wrapt in c:\\users\\anmrt\\desktop\\useful shit\\диплом\\graduation_thesis\\venv\\lib\\site-packages (from smart_open>=1.8.1->gensim) (2.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52cc2125",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b757231b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54434\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(df['tokens']) # Словарь\n",
    "print(len(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "611a7fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9824\n"
     ]
    }
   ],
   "source": [
    "# Фильтрация мловаря\n",
    "dictionary.filter_extremes(no_below=2, no_above=0.8)\n",
    "print(len(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a09bdfae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# Корпус\n",
    "corpus = [dictionary.doc2bow(tokens) for tokens in df['tokens']]\n",
    "print(len(corpus)) #размер корпуса в документах (шт)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cac4469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оценка качества\n",
    "\n",
    "# Вычисление когерентности (насколько хорошо слова в теме связаны между собой по смыслу)\n",
    "def evaluate_coherence(model, tokens: List[List[str]], dictionary, topn: int = 10) -> float:\n",
    "    from gensim.models.coherencemodel import CoherenceModel\n",
    "    \n",
    "    if hasattr(model, 'show_topics'):\n",
    "        # Для LDA, LSI\n",
    "        coherence_model = CoherenceModel(\n",
    "            model=model, \n",
    "            texts=tokens, \n",
    "            dictionary=dictionary, \n",
    "            coherence='c_v'\n",
    "        )\n",
    "    else:\n",
    "        # Для других моделей\n",
    "        topics = []\n",
    "        for topic_id in range(model.num_topics):\n",
    "            topic_words = model.get_topic_words(topic_id, topn=topn)\n",
    "            topics.append([word for word, _ in topic_words])\n",
    "        \n",
    "        coherence_model = CoherenceModel(\n",
    "            topics=topics, \n",
    "            texts=tokens, \n",
    "            dictionary=dictionary, \n",
    "            coherence='c_v'\n",
    "        )\n",
    "    \n",
    "    return coherence_model.get_coherence()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "354b3836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_topics(model, model_name: str, num_words: int = 10):\n",
    "    print(f\"\\n{model_name} - Темы:\")\n",
    "    \n",
    "    if hasattr(model, 'print_topics'):\n",
    "        # LDA\n",
    "        topics = model.print_topics(num_words=num_words)\n",
    "        for idx, topic in topics:\n",
    "            print(f\"Тема {idx}: {topic}\")\n",
    "    \n",
    "    elif hasattr(model, 'show_topics'):\n",
    "        # LSI\n",
    "        topics = model.show_topics(num_topics=-1, num_words=num_words, formatted=True)\n",
    "        for idx, topic in topics:\n",
    "            print(f\"Тема {idx}: {topic}\")\n",
    "    \n",
    "    elif hasattr(model, 'get_topics'):\n",
    "        # BigARTM\n",
    "        for topic_idx in range(model.num_topics):\n",
    "            topic_words = model.get_topic_words(topic_idx, num_words)\n",
    "            words = [f\"{word}({prob:.3f})\" for word, prob in topic_words]\n",
    "            print(f\"Тема {topic_idx}: {', '.join(words)}\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03467c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA\n",
      "Когерентность: 0.5210\n",
      "\n",
      "LDA - Темы:\n",
      "Тема 0: 0.004*\"мотивов\" + 0.004*\"правами\" + 0.004*\"учетными\" + 0.003*\"записями\" + 0.003*\"пальцев\" + 0.002*\"идентификации\" + 0.002*\"mediator\" + 0.002*\"nist\" + 0.002*\"разрешимости\" + 0.002*\"ладони\"\n",
      "Тема 1: 0.010*\"random\" + 0.005*\"coefficients\" + 0.005*\"see\" + 0.003*\"dependent\" + 0.003*\"матрицы\" + 0.003*\"sums\" + 0.003*\"sequence\" + 0.003*\"theorem\" + 0.003*\"vector\" + 0.003*\"one\"\n",
      "Тема 2: 0.004*\"тезауруса\" + 0.003*\"заявок\" + 0.003*\"traffic\" + 0.003*\"one\" + 0.003*\"географических\" + 0.002*\"random\" + 0.002*\"источников\" + 0.002*\"радиоисточников\" + 0.002*\"информационными\" + 0.002*\"электронных\"\n",
      "Тема 3: 0.009*\"rif\" + 0.004*\"правилах\" + 0.003*\"базы\" + 0.002*\"языка\" + 0.002*\"нечетких\" + 0.002*\"принадлежности\" + 0.002*\"s(1)\" + 0.002*\"библиотеки\" + 0.002*\"пакетов\" + 0.002*\"библиотек\"\n",
      "Тема 4: 0.000*\"rif\" + 0.000*\"random\" + 0.000*\"one\" + 0.000*\"языка\" + 0.000*\"средств\" + 0.000*\"coefficients\" + 0.000*\"базы\" + 0.000*\"theorem\" + 0.000*\"see\" + 0.000*\"мотивов\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LDA\n",
    "print(\"LDA\")\n",
    "\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "lda_model = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=dictionary,\n",
    "    num_topics=5,  # Можно настроить\n",
    "    random_state=42,\n",
    "    passes=10,\n",
    "    alpha='auto',\n",
    "    per_word_topics=True\n",
    ")\n",
    "\n",
    "# Оценка\n",
    "lda_coherence = evaluate_coherence(lda_model, df['tokens'], dictionary)\n",
    "print(f\"Когерентность: {lda_coherence:.4f}\")\n",
    "\n",
    "visualize_topics(lda_model, \"LDA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2821a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSI\n",
      "Когерентность LSI: 0.5594\n",
      "\n",
      "LSI - Темы:\n",
      "Тема 0: 0.201*\"rif\" + 0.182*\"random\" + 0.101*\"one\" + 0.094*\"мотивов\" + 0.094*\"правами\" + 0.090*\"учетными\" + 0.087*\"записями\" + 0.087*\"базы\" + 0.081*\"правилах\" + 0.079*\"средств\"\n",
      "Тема 1: 0.342*\"random\" + -0.314*\"rif\" + 0.170*\"see\" + 0.158*\"coefficients\" + -0.125*\"правилах\" + 0.113*\"one\" + 0.107*\"dependent\" + -0.102*\"базы\" + 0.100*\"theorem\" + 0.096*\"sums\"\n",
      "Тема 2: 0.215*\"rif\" + -0.190*\"мотивов\" + -0.185*\"правами\" + -0.180*\"учетными\" + -0.168*\"записями\" + -0.139*\"пальцев\" + -0.113*\"mediator\" + -0.113*\"идентификации\" + -0.100*\"nist\" + -0.098*\"ладони\"\n",
      "Тема 3: 0.218*\"rif\" + -0.203*\"тезауруса\" + 0.160*\"random\" + -0.159*\"заявок\" + -0.148*\"traffic\" + 0.144*\"coefficients\" + -0.124*\"географических\" + 0.115*\"see\" + -0.101*\"радиоисточников\" + -0.099*\"информационными\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#LSI\n",
    "print(\"LSI\")\n",
    "\n",
    "from gensim.models import LsiModel\n",
    "\n",
    "lsi_model = LsiModel(\n",
    "    corpus=corpus,\n",
    "    id2word=dictionary,\n",
    "    num_topics=5\n",
    ")\n",
    "\n",
    "lsi_coherence = evaluate_coherence(lsi_model, df['tokens'], dictionary)\n",
    "print(f\"Когерентность LSI: {lsi_coherence:.4f}\")\n",
    "\n",
    "visualize_topics(lsi_model, \"LSI\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
